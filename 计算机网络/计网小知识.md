<font color=red>纯搬运，原链接点标题</font>

# 1. [HTTP1.1，HTTP1.0，HTTP2.0](https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A)

**HTTP1.1的主要特性**:

1. **缓存处理**

   在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则**引入了更多的缓存控制策略**例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等**更多可供选择的缓存头**来**控制缓存策略**。

   ---

   **Last-Modified** 是由**服务器（缓存服务器）**发送给客户端的HTTP请求头标签

   **If-Modified-Since** 则是由客户端发送给服务器的HTTP请求头标签

   （1）**Last-Modified**

   在浏览器第一次请求某一个URL时，服务器端的返回状态会是200，内容是你请求的资源，同时有一个Last-Modified的属性标记此文件在服务期端最后被修改的时间，格式类似这样：

   Last-Modified: Fri, 12 May 2006 18:53:33 GMT

   后面跟的时间是服务器存储的文件修改时间

   （2）**If-Modified-Since**

   客户端第二次请求此URL时，根据 HTTP 协议的规定，浏览器会向服务器传送 If-Modified-Since 报头，询问该时间之后文件是否有被修改过：

   If-Modified-Since: Fri, 12 May 2006 18:53:33 GMT

   后面跟的时间是本地浏览器存储的文件修改时间

   如果服务器端的资源(**缓存服务器**)没有变化，则**时间一致**，自动**返回HTTP状态码304**（Not Changed.）状态码，**内容为空**，客户端接到之后，就直接把本地缓存文件显示到浏览器中，这样就节省了传输数据量。

   如果服务器端资源发生改变或者重启服务器时，**时间不一致**，就**返回HTTP状态码200**和**新的文件内容**，客户端接到之后，会丢弃旧文件，把新文件缓存起来，并显示到浏览器中。

   以上操作可以保证不向客户端重复发出资源，也保证当服务器有变化时，客户端能够得到最新的资源。

   ![image-20210410111444743](C:\Users\78620\AppData\Roaming\Typora\typora-user-images\image-20210410111444743.png)

   ---

   **If-Unmodified-Since**请求的HTTP标头发出请求的条件：服务器会发送回所请求的资源，或者接受它的情况下**POST**或其他非安全的方法，只要它没有被最后给定的日期之后修改。如果请求在给定日期之后被修改，则该响应将是**412**（先决条件失败）错误。

   ---

2. **带宽优化及网络连接的使用**

   HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头**引入了range头域**，它**允许只请求资源的某个部分**，即**返回码是206**（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

3. **错误通知的管理**

   在HTTP1.1中**新增了24个错误状态响应码**，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

4. **Host头处理**

   在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在**一台物理服务器**上可以存在**多个虚拟主机**（Multi-homed Web Servers），并且它们**共享一个IP地址**。**HTTP1.1的请求消息和响应消息都应支持Host头域**，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。

5. **长连接**

   HTTP 1.1**支持长连接**（PersistentConnection）和**请求的流水线**（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中**默认开启Connection： keep-alive**，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。
   
   ![HTTP的管线化（pipelining）技术](https://www.maixj.net/pics/uploads/2019/06/http_pipelining.jpg)

# 2. HTTPS和HTTP的区别

- HTTPS协议**需要到CA申请证书**，一般免费证书很少，需要交费。
- HTTP协议运行在TCP之上，所有传输的内容都是明文，HTTPS运行在SSL/TLS之上，SSL/TLS运行在TCP之上，所有传输的内容都经过加密的。
- HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是**80**，后者是**443**。
- HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。

![图片](https://mmbiz.qlogo.cn/mmbiz_png/cmOLumrNib1cfBOtIMQ6JfSibJdd6QkQribXL5PwzkqQdmyY9egu2hpzzMCgz2F5HhhkdSNc5eYJ9UGMDBGjeCGiag/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1&retryload=2)

# 3. [HTTP队头阻塞(HOL BLOCK)](https://cloud.tencent.com/developer/article/1509279)

在一般情况下，HTTP遵守“**请求-响应**”的模式，也就是客户端每次发送一个请求到服务端，服务端返回响应，这种模式很简单，但是有一个致命缺陷那就是**页面中有多个请求**，**每个请求必须等到前一个请求响应之后才能发送，并且当前请求的响应返回之后，当前请求的下一个请求才能发送**，流程如下图：

![image-20210410162753867](C:\Users\78620\AppData\Roaming\Typora\typora-user-images\image-20210410162753867.png)

仔细观察上图：在tcp链接中，http请求必须等待前一个请求响应之后，才能发送，后面的依次类推，由此可以看出，如果在一个tcp通道中如果某个http请求的响应因为某个原因没有及时返回，后面的响应会被阻塞，这就是**队头阻塞**。

![image-20210410163153807](C:\Users\78620\AppData\Roaming\Typora\typora-user-images\image-20210410163153807.png)

1. 首先我们厘清了一个概念，那就是http长连接其实指的是tcp长连接。
2. 队头阻塞是一种现象，http因为请求-响应模型会有队头阻塞的现象出现，队头阻塞指的是**在同一个tcp链接中，如果先发送的http请求如果没有响应的话，后面的http请求也不会响应**。
3. 解决队头阻塞的第一个方案就是并发长连接，浏览器默认是6-8个长连接，我们可以用域名分片的技术突破这个数值。
4. 并发长连接虽然在一定程度上解决了http的队头阻塞，但是会对服务器的性能有较高的要求。

# 4. [HTTP2.0](https://segmentfault.com/a/1190000016656529)

​	**HTTP1.X的缺点**

​	HTTP1.x有以下几个主要缺点：

- HTTP/1.0一次只允许在一个TCP连接上发起一个请求，HTTP/1.1使用的流水线技术也只能部分处理请求并发，仍然会存在队列头阻塞问题，因此客户端在需要发起多次请求时，通常会采用建立多连接来减少延迟。

- 单向请求，只能由客户端发起。
- 请求报文与响应报文首部信息冗余量大。
- 数据未压缩，导致数据的传输量大

1. **二进制传输**

   在不改变HTTP1.x的语义、方法、状态码、URL以及首部字段的情况下，HTTP2.0是怎样突破HTTP1.1的性能限制，改进传输性能，实现低延迟高吞吐量的呢？**关键之一就是在应用层（HTTP）和传输层（TCP）之间增加一个二进制分帧层**。

   在整理二进制分帧及其作用的时候我们先来铺垫一点关于帧的知识：

   - **帧**：HTTP2.0通信的最小单位，所有帧都共享一个8字节的首部，其中包含帧的长度、类型、标志、还有一个保留位，并且至少有标识出当前帧所属的流的标识符，帧承载着特定类型的数据，如HTTP首部、负荷、等等。
   - **消息**：比帧大的通讯单位，是指逻辑上的HTTP消息，比如请求、响应等。由一个或多个帧组成
   - **流**：比消息大的通讯单位。是TCP连接中的一个虚拟通道，可以承载双向的消息。每个流都有一个唯一的整数标识符

   HTTP2.0中所有加强性能的核心是**二进制传输**，在HTTP1.x中，我们是通过文本的方式传输数据。基于文本的方式传输数据存在很多缺陷，文本的表现形式有多样性，因此要做到健壮性考虑的场景必然有很多，但是二进制则不同，只有0和1的组合，因此选择了二进制传输，实现方便且健壮。
   在HTTP2.0中引入了新的编码机制，**所有传输的数据都会被分割，并采用二进制格式编码**。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190802162333949.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lleHVkZW5nemhpZGFv,size_16,color_FFFFFF,t_70)

​	为了保证HTTP不受影响，那就需要在应用层（HTTP2.0）和传输层（TCP or UDP）之间增加一个二进制分帧层。**在二进制分帧层上，HTTP2.0会将所有传输的信息分为更小的消息和帧，并采用二进制格式编码，其中HTTP1.x的首部信息会被封装到Headers帧，而Request Body则封装到Data帧**。

2. **首部压缩**

   HTTP1.1并不支持HTTP首部压缩，为此SPDY和HTTP2.0出现了。SPDY是用的是DEFLATE算法，而HTTP2.0则使用了专门为首部压缩设计的HPACK算法。

   HTTP每次通讯（请求或响应）都会携带首部信息用于描述资源属性。

   在HTTP1.0中，我们使用文本的形式传输header，**在header中携带cookie的话，每次都需要重复传输几百到几千的字节，这着实是一笔不小的开销**。

   在HTTP2.0中，我们使用了**[HPACK](https://blog.csdn.net/qq_38937634/article/details/111410191?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0&spm=1001.2101.3001.4242)（HTTP2头部压缩算法）**压缩格式**对传输的header进行编码**，减少了header的大小。并在两端维护了索引表，用于记录出现过的header，后面在传输过程中就可以传输已经记录过的header的**键名**，对端收到数据后就可以通过键名找到对应的值。

3. **多路复用**

   在HTTP1.0中，我们经常会使用到雪碧图、使用多个域名等方式来进行优化，都是因为浏览器限制了同一个域名下的请求数量，当页面需要请求很多资源的时候，队头阻塞（Head of line blocking）会导致在达到最大请求时，资源需要等待其他资源请求完成后才能继续发送。
   HTTP2.0中，有两个概念非常重要：**帧（frame）**和**流（stream）**。
   帧是最小的数据单位，每个帧会标识出该帧属于哪个流，流是多个帧组成的数据流。
   所谓**多路复用**，即**<font color=red>在一个TCP连接中存在多个流</font>**，即**可以同时发送多个请求**，**对端可以通过帧中的表示知道该帧属于哪个请求**。在客户端，这些帧乱序发送，到对端后再**根据每个帧首部的流标识符重新组装**。通过该技术，可以**避免HTTP旧版本的队头阻塞问题**，极大提高传输性能。

![图片描述](https://segmentfault.com/img/bVbgpF3?w=494&h=138)



4. **服务器push**

   在HTTP2.0中，服务端可以**在接收客户端某个请求后，主动推送其他资源**。
   可以想象一下，某些资源客户端是一定会请求的，这时就可以采取服务端push的技术，提前给客户端推送必要的资源，就可以相对减少一点延迟时间。在浏览器兼容的情况下也可以使用prefetch。

5. **更安全**

   HTTP2.0使用了tls的拓展ALPN做为协议升级，除此之外，HTTP2.0对tls的安全性做了近一步加强，**通过黑名单机制禁用了几百种不再安全的加密算法**。

# 5. [Google QUIC](https://www.cnblogs.com/imteck4713/p/11777310.html)

[公钥和密钥](https://www.cnblogs.com/moonfans/p/3939335.html)

[数字签名和数字证书](http://www.ruanyifeng.com/blog/2011/08/what_is_a_digital_signature.html)

[数字签名和数字证书2](https://www.cnblogs.com/MicroHeart/p/9057189.html)

[技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解](http://www.52im.net/thread-1309-1-1.html)



# 6. 内网穿透(NAT穿透)

1. [内网和外网](https://blog.csdn.net/weixin_43803070/article/details/90404645?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161879903016780262531711%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161879903016780262531711&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-90404645.first_rank_v2_pc_rank_v29&utm_term=%E5%86%85%E7%BD%91%E5%92%8C%E5%A4%96%E7%BD%91&spm=1018.2226.3001.4187)

# 7. 负载均衡—一致性Hash算法

1. [视频讲解](https://www.bilibili.com/video/BV1Hs411j73w)
2. [blog](https://blog.csdn.net/monokai/article/details/106626945)

# 8. [**CDN**(内容分发网)](https://blog.csdn.net/qq_38987057/article/details/85317970)

![在这里插入图片描述](https://img-blog.csdnimg.cn/2018122810200917.gif)

# 9. [DHCP(动态主机配置协议)](https://blog.csdn.net/qq_24421591/article/details/50936469)

1. **DHCP简介**

   **DHCP(Dynamic Host Configuration Protocol),动态主机配置协议**，是一个应用层协议。当我们将客户主机ip地址设置为动态获取方式时，DHCP服务器就会根据DHCP协议给客户端分配IP，使得客户机能够利用这个IP上网。

2. **DHCP实现**

   ![这里写图片描述](https://img-blog.csdn.net/20160321233138127)

   DHCP的实现分为4步，分别是： 
   第一步：Client端在局域网内发起一个**DHCP Discover**包，目的是想发现能够给它提供IP的**DHCP Server**。 
   第二步：可用的DHCP Server接收到Discover包之后，通过发送**DHCP Offer**包给予Client端应答，意在告诉Client端它可以提供IP地址。 
   第三步：Client端接收到Offer包之后，发送**DHCP Request**包请求分配IP。 
   第四步：DHCP Server发送ACK数据包，确认信息。

   **注意DHCP使用UDP实现**

# 10. [DNS(域名解析协议)](https://blog.csdn.net/baidu_37964071/article/details/80500825?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161879777016780264036229%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161879777016780264036229&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-80500825.first_rank_v2_pc_rank_v29&utm_term=DNS&spm=1018.2226.3001.4187)

**如果说ARP协议是用来将IP地址转换为MAC地址，那么DNS协议则是用来将域名转换为IP地址（也可以将IP地址转换为相应的域名地址）。**

1. **域名解析过程**
   域名解析总体可分为一下过程：

   (1) 输入域名后, 先查找自己主机对应的域名服务器，域名服务器先查找自己的数据库中的数据.

   (2) 如果没有， 就向上级域名服务器进行查找， 依次类推

   (3) 最多回溯到根域名服务器, 肯定能找到这个域名的IP地址

   (4) 域名服务器自身也会进行一些缓存， 把曾经访问过的域名和对应的IP地址缓存起来, 可以加速查找过程

   **具体可描述如下**：

   1. 主机先向本地域名服务器进行递归查询
   2. 本地域名服务器采用迭代查询，向一个根域名服务器进行查询
   3. 根域名服务器告诉本地域名服务器，下一次应该查询的顶级域名服务器的IP地址
   4. 本地域名服务器向顶级域名服务器进行查询
   5. 顶级域名服务器告诉本地域名服务器，下一步查询权限服务器的IP地址
   6. 本地域名服务器向权限服务器进行查询
   7. 权限服务器告诉本地域名服务器所查询的主机的IP地址
   8. 本地域名服务器最后把查询结果告诉主机

   ![这里写图片描述](https://img-blog.csdn.net/20180529191603529?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JhaWR1XzM3OTY0MDcx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



# 11. [ARP(地址解析协议)](https://blog.csdn.net/lm409/article/details/80299823?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161879954016780366547320%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=161879954016780366547320&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-80299823.first_rank_v2_pc_rank_v29&utm_term=ARP&spm=1018.2226.3001.4187)

地址解析协议（Address Resolution Protocol），其基本功能为透过目标设备的IP地址，查询目标设备的MAC地址，以保证通信的顺利进行。它是IPv4中网络层必不可少的协议，不过在IPv6中已不再适用，并被邻居发现协议（NDP）所替代。

假设主机A和B在同一个网段，主机A要向主机B发送信息，具体的地址解析过程如下：
(1) 主机A首先**查看自己的ARP表**，确定其中是否包含有主机B对应的ARP表项。如果找到了对应的MAC地址，则主机A直接利用ARP表中的MAC地址，对IP数据包进行帧封装，并将数据包发送给主机B。

(2) 如果主机A在ARP表中找不到对应的MAC地址，则将缓存该数据报文，然后以广播方式发送一个ARP请求报文。**ARP请求报文中的发送端IP地址和发送端MAC地址为主机A的IP地址和MAC地址，目标IP地址和目标MAC地址为主机B的IP地址和全0的MAC地址**。由于ARP请求报文以**广播**方式发送，该网段上的所有主机都可以接收到该请求，但只有被请求的主机（即主机B）会对该请求进行处理。

(3) 主机B比较自己的IP地址和ARP请求报文中的目标IP地址，当两者相同时进行如下处理：将ARP请求报文中的发送端（即主机A）的IP地址和MAC地址存入自己的ARP表中。之后以**单播**方式发送ARP响应报文给主机A，其中包含了自己的MAC地址。

(4) 主机A收到ARP响应报文后，将主机B的MAC地址加入到自己的ARP表中以用于后续报文的转发，同时将IP数据包进行封装后发送出去。

# 12. [高性能服务器](https://blog.csdn.net/zz_vim/article/details/89089122)

<h3>一. 单台服务器+数据库（原始）</h3>

![原始架构](https://img-blog.csdnimg.cn/2019040814535866.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6X3ZpbQ==,size_16,color_FFFFFF,t_70)

<div align = "center">原始架构</div>			

<h3>二. 增加反向代理</h3>

1. **[正向代理和反向代理](https://blog.csdn.net/clevercode/article/details/77747786?ops_request_misc=&request_id=&biz_id=102&utm_term=%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E5%92%8C%E6%96%B9%E5%90%91%E4%BB%A3%E7%90%86&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-77747786.first_rank_v2_pc_rank_v29&spm=1018.2226.3001.4187)**

   - **正向代理**

     用户访问不了目标机器，需要通过代理服务器作为跳板，访问目标机器。（用户访问代理服务器，代理服务器请求目标机器，然后将请求的结果返回给用户）

     ![img](https://img-blog.csdn.net/20170831154852005)

   - **反向代理**

     用户访问目标机器，目标机器不做处理，从后端真正的机器上获取数据，然后返回给用户。这样可以隐藏真实的目标机器。（通常的做法可以负载均衡）

     ![img](https://img-blog.csdn.net/20170831155008254)

     



​		代理是一个接收和转发请求的过程。正常情况下，**「正向代理」代理的对象是客户端**，**「反向代理」代理的对象是服务端**，它完成这些功能：

- 健康检查功能，确保我们的服务器是一直处于运行状态的
- 路由转发功能，把请求转发到正确的服务路径上
- 认证功能，确保用户有权限访问后端服务器
- 防火墙功能，确保用户只能访问允许使用的网络部分等等

<h3>三. 引入负载均衡器</h3>

![img](https://img-blog.csdnimg.cn/2019040814563171.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6X3ZpbQ==,size_16,color_FFFFFF,t_70)

反向代理还有另外一个功能：他们也可以充当负载均衡器。

Nginx经过配置，可以反向代理多台服务器。

部署多台Nginx（反向代理服务器），防止宕机，提升系统运行稳定性。

**一致性哈希算法，见上**

<h3>四. 扩展数据库</h3>

![img](https://img-blog.csdnimg.cn/20190408145716479.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6X3ZpbQ==,size_16,color_FFFFFF,t_70)

​	负载均衡器的使用使得我们可以在多个服务器之间分配负载，但是现在所有的服务器还是使用的一个数据库进行存储和检索数据。我们可以用同样的方式，再**扩展几台数据库出来**，**减轻存储检索压力**，但是这里存在一个<font color=red>数据一致性</font>的问题。

(1) 主从模式或者单实例写多副本读

​	其中**一台数据库负责数据写入修改**，**其他服务器负责读**，这个方案的好处是**保证了一致性**，因为数据只能被单实例一台数据库写入，之后把写入数据同步到其他部分即可，所以该方案适合**读多写少**的情景。

 I、如何进行同步？

![img](https://img-blog.csdnimg.cn/20190408145809735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6X3ZpbQ==,size_16,color_FFFFFF,t_70)同步机制



 <div align = "center">同步机制</div>			

 	通过使用消息队列进行异步数据同步，来实现数据的最终一致性。当然消息队列的各种异常也会造成数据不一致，所以我们又引入了实时监控服务，实时计算两个集群的数据差异，并进行一致性同步。

   II、主从模式弊病

![img](https://img-blog.csdnimg.cn/20190408145850147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6X3ZpbQ==,size_16,color_FFFFFF,t_70)

<div align = "center">主从模式架构</div>			

​	当主库DB1出现问题时，DBA会将DB2切换为主库，并通知项目组，项目组使用DB2替换原有的主库DB1，重启web服务器，这样web服务将使用新的主库DB2，而DB1将不再被访问，整个数据库服务得到恢复，等DBA修复DB1时，再将DB1作为DB2的从库即可。

​	这里有个很大的问题，就是不管主库或从库出现问题，都需要DBA和项目组协同完成数据库服务恢复，这很难做到自动化，而且恢复工程也过于缓慢。

​	<font color=red>所以数据库如何做到高可用呢？</font>

​	**高可用HA**（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，**通过设计减少系统不能提供服务的时间**。

​	![img](https://img-blog.csdnimg.cn/20190408145930284.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6X3ZpbQ==,size_16,color_FFFFFF,t_70)

<div align = "center">数据库高可用架构</div>			

​	如上图所示，web服务器将不再直接连接主库DB1，而是**连接KeepAlive虚拟出的一个虚拟ip**，再将此虚拟ip映射到主库DB1上，同时添加DB_bak从库，实时同步DB1中的数据。正常情况下web还是在DB1中读写数据，**当DB1宕机后，脚本会自动将DB_bak设置成主库，并将虚拟ip映射到DB_bak上**，web服务将使用健康的DB_bak作为主库进行读写访问。这样只需几秒的时间，就能完成主数据库服务恢复。

​	同样的，web服务器将不再直接连接从库DB2和DB3，而是连接LVS负载均衡，由LVS连接从库。这样做的好处是LVS能自动感知从库是否可用，从库DB2宕机后，LVS将不会把读数据请求再发向DB2。同时DBA需要增减从库节点时，只需独立操作LVS即可，不再需要项目组更新配置文件，重启服务器来配合。

（2）分库分表操作

​    参考：

​	https://www.cnblogs.com/zhangj391/p/6715410.html

​	https://www.jianshu.com/p/32b3e91aa22c

<h3>五. 微服务</h3>

​	将所有服务放在一个服务器上，放在一个JAR包，降低了复杂性，但是随着规模的增加，事情会变得复杂和低效，更多的开发人员加入进来，在同一台服务器同一个项目代码里面进行开发，造成的冲突会越来越多，互相依赖性太高，同时不利于新入开发人员阅读理解代码。

​	这时候微服务架构产生了。

![img](https://img-blog.csdnimg.cn/20190408150024798.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6X3ZpbQ==,size_16,color_FFFFFF,t_70)

<div align = "center">微服务架构</div>			

- 每个服务都可以单独扩展，更好地适应需求
- 开发团队之间相互独立，每个团队都负责自己的微服务生命周期(创建，部署，更新）等。
- 每个微服务都有自己的资源，比如数据库，进一步缓解了数据库的问题。

<font color=red>微服务的划分大多是**基于业务进行拆分**，**实现低耦合**。</font>

<h3>六. 缓存和内容分发网（CDN)</h3>

![img](https://img-blog.csdnimg.cn/20190408150144929.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6X3ZpbQ==,size_16,color_FFFFFF,t_70)

​	网络应用的很大一部分由静态资源构成,如图片、CSS样式文件、JavaScript脚本以及一些针对特定产品提前渲染好的页面等，通过使用缓存，对于一些客户的请求，不一定都去重新处理一遍，使用缓存，提高访问速度。

​	缓存的加强版叫**内容分发网络**（Content Delivery Network），遍布全球的大量缓存。 这使得用户可以**从物理上靠近他们的地方来获取网页内容**，而不是每次都把数据从源头搬到用户那里。

<h3>七. 消息队列</h3>

![img](https://img-blog.csdnimg.cn/2019040815022169.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3p6X3ZpbQ==,size_16,color_FFFFFF,t_70)

**将客户的任务请求放到一个队列当中，进行管理任务**，优点：

- 解耦了任务和处理过程。有时需要处理大量的图片，有时很少。有时有大量服务可用，有时很少可用。简单地把任务添加到待办事项而不是直接处理它们，这确保了系统保持响应并且任务也不会丢失。
- 可以按需扩展。启动大量的服务比较耗时，所以当有大量用户上传图片时再去启动服务，这已经太晚了。我们把任务添加到队列中，我们可以推迟提供额外的处理能力。



# 13. [浏览器输入网址后会发生什么](https://segmentfault.com/a/1190000012092552)

1. DNS域名解析
2. 建立TCP链接(三次握手)
3. 发送HTTP请求
4. 服务器处理请求
5. 返回响应结果
6. 关闭TCP连接(四次挥手)
7. 浏览器解析HTML
8. 浏览器布局渲染

# 14. [HTTPS](https://leetcode-cn.com/leetbook/read/tech-interview-cookbook/opva47/)

![image](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/How-HTTPS-Works.png)

# 15.数字签名和数字证书

以下图为自绘

![image-20210814234315281](C:\Users\78620\AppData\Roaming\Typora\typora-user-images\image-20210814234315281.png)

# 16. TCP长连接，HTTP长连接，websocket长连接

1. **HTTP长连接**

在HTTP/1.0中，默认使用的是短连接。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话。

但从 HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：

> Connection:keep-alive

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。

HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。

2. **TCP长连接**

我们模拟一下TCP短连接的情况，client向server发起连接请求，server接到请求，然后双方建立连接。client向server 发送消息，server回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close操作，不过一般都是client先发起 close操作。为什么呢，一般的server不会回复完client后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接一般只会在 client/server间传递一次读写操作

短连接的优点是：管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段

接下来我们再模拟一下长连接的情况，client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。

首先说一下TCP/IP详解上讲到的TCP保活功能，保活功能主要为服务器应用提供，服务器应用希望知道客户主机是否崩溃，从而可以代表客户使用资源。如果客户已经消失，使得服务器上保留一个半开放的连接，而服务器又在等待来自客户端的数据，则服务器将应远等待客户端的数据，保活功能就是试图在服务 器端检测到这种半开放的连接。

3. **WebSocket长连接**

Websocket是html5提出的一个协议规范，是为解决客户端与服务端实时通信。本质上是一个基于tcp，先通过HTTP/HTTPS协议发起一条特殊的http请求进行握手后创建一个用于交换数据的TCP连接。

WebSocket优势： 浏览器和服务器只需要要做一个握手的动作，在建立连接之后，双方可以在任意时刻，相互推送信息。同时，服务器与客户端之间交换的头信息很小。

HTTP1.1通过使用Connection:keep-alive进行长连接，HTTP 1.1默认进行持久连接。在一次 TCP 连接中可以完成多个 HTTP 请求，但是对每个请求仍然要单独发 header，Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。这种长连接是一种“伪链接”

websocket的长连接，是一个真的全双工。长连接第一次tcp链路建立之后，后续数据可以双方都进行发送，不需要发送请求头。

keep-alive双方并没有建立正真的连接会话，服务端可以在任何一次请求完成后关闭。WebSocket 它本身就规定了是正真的、双工的长连接，两边都必须要维持住连接的状态。

# 17. [TCP拥塞控制，流量控制](https://zhuanlan.zhihu.com/p/37379780)

# 18. UDP，TCP，IP头部

(1) UDP

![在这里插入图片描述](https://img-blog.csdnimg.cn/2021030809185216.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUzNzI1OA==,size_16,color_FFFFFF,t_70)

**UDP长度包括首部在内的UDP报文段长度(字节为单位)**

校验和，发送方将报文段中所有的16比特字进行求和，在反码运算。

(2) TCP

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210308095318405.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUzNzI1OA==,size_16,color_FFFFFF,t_70)

TCP可以从缓存中取出并放入报文段中的数据数量受限于**最大报文段长度(MSS)**

而MSS通常根据最初确定的由本地发送主机发送的**最大链路层帧长度（最大传输单元MTU）来设置**

以太网和PPP链路层协议都具有1500字节的**最大传输单元MTU**，减掉TCP+IP 40字节的头部，则剩下的**最大报文段长度（MSS）为1460**

![image-20210828113321419](C:\Users\78620\AppData\Roaming\Typora\typora-user-images\image-20210828113321419.png)

16位窗口大小用于**流量控制**，指示接收方愿意接受的字节数量。

注意，若接收方B的窗口大小为0，则此时理论上发送方A就不会继续发送TCP数据了。但是如果这样A不发TCP数据给B,则B就不可能通过ACK来告诉A他的接收窗口已经不为0了。

因此TCP规范要求：**若接收方窗口大小为0，则发送方会继续发送只有一个字节数据的报文段。这个报文段会被接收方确认。最终当接收方缓存清空时，会在确认报文段里面包含一个非0的rwnd值**

**TCP头部标志位**

- URG,紧急指针

- ACK，确认号
- PSH，接收端应用程序应该立即从TCP接受缓冲区读走数据
- RST，表示要求对方重新建立连接
- SYN，请求建立一个连接
- FIN，通知对方本端要关闭连接了。

(3) IP

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191120135518410.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDEzNTU0NA==,size_16,color_FFFFFF,t_70)

# 19. [socket通信与三次握手四次挥手](https://www.cnblogs.com/niwotaxuexiba/p/9700764.html)

![image](https://images.cnblogs.com/cnblogs_com/skynet/201012/201012122157476286.png)

![image](https://images.cnblogs.com/cnblogs_com/skynet/201012/201012122157494693.png)

# 20. [TCP拥塞控制算法](https://blog.csdn.net/qq_41431406/article/details/97926927)

1. 超时

cwnd变为1，ssthresh变为一半，**慢启动**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190604094130199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzg2MzAw,size_16,color_FFFFFF,t_70)

2. 3ACK

区别：新的 TCP Reno 版本在**快重传**之后采用**快恢复**算法而不是采用慢开始算法。

也有的快重传实现是把开始时的拥塞窗口cwnd值再增大一点，即等于 **ssthresh + 3 X MSS **。这样做的理由是：既然发送方收到三个重复的确认，就表明有三个分组已经离开了网络。这三个分组不再消耗网络 的资源而是停留在接收方的缓存中。可见现在网络中并不是堆积了分组而是减少了三个分组。因此可以适当把拥塞窗口扩大了些。

下面二图都是为不加3MSS版本

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190604100440751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxMzg2MzAw,size_16,color_FFFFFF,t_70)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190731184935595.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

# 21. [TCP出现RST的情况](https://my.oschina.net/costaxu/blog/127394)

1. 端口未打开
2. 请求超时
3. 提前关闭
4. 在一个已关闭的socket上收到数据

# 22. TCP握手时可以携带数据吗

■ 初始状态：客户端处于 closed(关闭)状态，服务器处于 listen(监听) 状态。

■第一次握手：客户端发送请求报文将 SYN = 1同步序列号和初始化序列号seq = x发送给服务端，发送完之后客户端处于SYN_Send状态。（验证了客户端的发送能力和服务端的接收能力）

■第二次握手：服务端受到 SYN 请求报文之后，如果同意连接，会以自己的同步序列号SYN(服务端) = 1、初始化序列号 seq = y和确认序列号（期望下次收到的数据包）ack = x+ 1 以及确认号ACK = 1报文作为应答，服务器为SYN_Receive状态。

■第三次握手： 客户端接收到服务端的 SYN + ACK之后，知道可以下次可以发送了下一序列的数据包 了，然后发送同步序列号 ack= y + 1和数据包的序列号 seq = x + 1以及确认号ACK = 1确认包作为 应答，客户端转为established状态。

**第三次握手的时候，是可以携带数据的**。但是，第一次、第二次握手 不可以携带数据。

RFC793文档里**带有SYN标志的过程包**是不可以携带数据的，也就是说三次握手的前两次是不可以携带数据的。

这是因为：第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击了。而对于第三次的话，此时客户端已经处于 ESTABLISHED 状态。对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据也没啥毛病。

# 23.TCP三次握手，四次挥手

![img](https://img-blog.csdn.net/20170104214009596?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2h1c2xlaQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

**其中ISN为随机初始序列号**

![这里写图片描述](https://img-blog.csdn.net/20171207143536572?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdm9pZHJldHVybg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

握手状态

![这里写图片描述](https://img-blog.csdn.net/20171207143424301?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdm9pZHJldHVybg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

# 24.[TCP三次握手的ISN](https://www.zhihu.com/question/271701044)

**ISN代表什么？意义何在？**

ISN，发送方的字节数据编号的原点，让对方生成一个合法的接收窗口。

**ISN是固定不变的吗？**

动态随机。

**ISN为何要动态随机？**

增加安全性，为了避免被第三方猜测到，从而被第三方伪造的RST报文Reset。

**还有吗？**

ISN动态随机使得每个tcp session的字节序列号没有重叠，如果出现tcp五元组冲突这种极小概率情况的发生，一个session的数据也不会被误认为是另一个session的。

**第三次可以携带数据吗？为何？**

可以。

能够发出第三次握手报文的主机，肯定接收到第二次(服务器)握手报文，对吗？

因为伪造IP的主机是不会接收到第二次报文的。

所以，能够发出第三次握手报文的，应该是合法的用户。

尽管服务器侧的状态还没有“established”，接收到第三次握手的瞬间，状态就会切换为“established”，里面携带的数据按照正常流程走就好。  

**看到有人说，只看到过TCP状态位为** **’FIN +ACK’，但从来没有看过状态位只有** **‘FIN’，你应该怎样给他解释？**

RFC793明确规定，除了第一个握手报文SYN除外，其它所有报文必须将ACK = 1。

**很好，RFC规定的背后肯定有合理性的一面，能否深究一下原因？**

TCP作为一个可靠传输协议，其可靠性就是依赖于收到对方的数据，ACK对方，这样对方就可以释放缓存的数据，因为对方确信数据已经被接收到了。

但TCP报文是在IP网络上传输，丢包是家常便饭，接收方**要抓住一切的机会，把消息告诉发送方**。最方便的方式就是，任何我方发送的TCP报文，都要捎带着ACK状态位。

**ACK状态位单独能承担这个消息传递的任务吗？**

不能！需要有 Acknowledge Number配合才行。

如果我方发出的Acknowledge Number == 10001，那意味着序列号10000及之前的字节已经成功接收。

如果对方占据字节序列号10000是应用层数据，那么就是确认应用层数据。

如果对方占据字节序列号10000是’FIN’状态位，那么就是确认接收到对方的’FIN’。

# 25. 为什么一定是三次握手

三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而**三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的**

1. 第一次握手，发送端：什么都确认不了；接收端：**对方发送正常，自己接受正常** 
2. 第二次握手，发送端：**对方发送，接受正常，自己发送，接受正常** ；接收端：对方发送正常，自己接受正常 
3. 第三次握手，发送端：对方发送，接受正常，自己发送，接受正常；接收端：**对方**发送，**接受正常**，**自己发送**，接受正常

两次握手不行吗？为什么TCP[客户端]()最后还要发送一次确认呢？

主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误。
经典场景：**[客户端]()发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了**

- 由于TCP的[客户端]()迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后[客户端]()和服务器经过两次握手完成连接，传输数据，然后关闭连接。 
- 此时此前滞留的那一次请求连接，网络通畅了到达服务器，这个报文本该是失效的，但是，两次握手的机制将会让[客户端]()和服务器再次建立连接，这将导致不必要的错误和资源的浪费。 
- 如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是[客户端]()不会再次发出确认。由于服务器收不到确认，就知道[客户端]()并没有请求连接。

# 26. 如何解决SYN洪范攻击

**SYN cookies技术**： 

1. **当服务器接受到 SYN 报文段时，不直接为该 TCP 分配资源**，而只是打开一个半开的套接字。接着会使用 SYN 报文段的源 Id，目的 Id，端口号以及只有服务器自己知道的一个秘密函数**生成一个 cookie，并把 cookie 作为序列号响应给[客户端]()**。 
2. **如果[客户端]()是正常建立连接，将会返回一个确认字段为 cookie + 1 的报文段**。接下来服务器会根据确认报文的源 Id，目的 Id，端口号以及秘密函数计算出一个结果，**如果结果的值 + 1 等于确认字段的值，则证明是刚刚请求连接的[客户端]()，这时候才为该 TCP 分配资源**

# 27. TCP三次握手中，最后一次回复丢失，会发生什么？

- 如果最后一次ACK在网络中丢失，那么**Server端（服务端）该TCP连接的状态仍为SYN_RECV**，并且**根据 TCP的超时重传机制依次等待3秒、6秒、12秒后重新发送 SYN+ACK 包**，以便 **Client（[客户端]()）重新发送ACK包** 
- **如果重发指定次数后，仍然未收到ACK应答**，那么一段时间后，**Server（服务端）自动关闭这个连接** 
- **但是Client（[客户端]()）认为这个连接已经建立**，如果Client（[客户端]()）端向Server（服务端）发送数据，**Server端（服务端）将以RST包（Reset，标示复位，用于异常的关闭连接）响应**，此时，[客户端]()知道第三次握手失败

# 28. 为什么连接的时候是三次握手，关闭的时候却是四次握手？

- 建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把**ACK和SYN放在一个报文里**发送给[客户端]()。 
- 关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了,所以服务器可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接。因此，服务器**ACK和FIN一般都会分开发送**，从而导致多了一次。

# 29. 为什么TCP挥手每两次中间有一个 FIN-WAIT2等待时间？

- 主动关闭的一端调用完close以后（即发FIN给被动关闭的一端， 并且收到其对FIN的确认ACK）则进入FIN_WAIT_2状态。**如果这个时候因为网络突然断掉、被动关闭的一段宕机等原因，导致主动关闭的一端不能收到被动关闭的一端发来的FIN（防止对端不发送关闭连接的FIN包给本端）**，这个时候就需要FIN_WAIT_2定时器， 如果在该定时器超时的时候，还是没收到被动关闭一端发来的FIN，那么直接释放这个链接，进入CLOSE状态



# 30. 为什么[客户端]()最后还要等待2MSL？为什么还有个TIME-WAIT的时间等待？

1. **保证[客户端]()发送的最后一个ACK报文能够到达服务器**，因为这个ACK报文可能丢失，**服务器已经发送了FIN+ACK报文，请求断开，[客户端]()却没有回应，于是服务器又会重新发送一次，而[客户端]()就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文**，并且会重启2MSL计时器。 
2. 防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。[客户端]()发送完最后一个确认报文后，在这个2MSL时间中，就可以**使本连接持续的时间内所产生的所有报文段都从网络中消失，这样新的连接中不会出现旧连接的请求报文**。 
3. 2MSL，最大报文生存时间，一个MSL 30 秒，2MSL = 60s 

# 31. [客户端]() TIME-WAIT 状态过多会产生什么后果？怎样处理？

1. 作为服务器，短时间内关闭了大量的Client连接，就会造成服务器上出现大量的TIME_WAIT连接，**占据大量的tuple /tApl/ ，严重消耗着服务器的资源**，此时部分[客户端]()就会显示连接不上 
2. 作为[客户端]()，短时间内大量的短连接，会大量消耗的Client机器的端口，毕竟端口只有65535个，端口被耗尽了，后续就无法在发起新的连接了 

- 高并发短连接

    的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。这个场景下会出现大量socket处于TIME_WAIT状态。如果[客户端]()的并发量持续很高，

    此时部分[客户端]()就会显示连接不上

    - **高并发可以让服务器在短时间范围内同时占用大量端口**，而端口有个0~65535的范围，并不是很多，刨除系统和其他服务要用的，剩下的就更少了 
    - **短连接表示“业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间”的连接** 

- 解决方法：  

    - 用负载均衡来抗这些高并发的短请求； 
    - 服务器可以设置 SO_REUSEADDR 套接字选项来避免 TIME_WAIT状态，TIME_WAIT 状态可以通过优化服务器参数得到解决，因为发生TIME_WAIT的情况是服务器自己可控的，要么就是对方连接的异常，要么就是自己没有迅速回收资源，总之不是由于自己程序错误导致的 
    - 强制关闭，发送 RST 包越过TIMEWAIT状态，直接进入CLOSED状态 

# 32. 服务器出现了大量 CLOSE_WAIT 状态如何解决？

- **大量 CLOSE_WAIT 表示程序出现了问题**，对方的 socket 已经关闭连接，而我方忙于读或写没有及时关闭连接，需要检查代码，特别是释放资源的代码，或者是处理请求的线程配置。 

# 33. 服务端会有一个TIME_WAIT状态吗？如果是服务端主动断开连接呢？

- 发起链接的主动方基本都是[客户端]()，但是**断开连接的主动方服务器和[客户端]()都可以充当**，也就是说，**只要是主动断开连接的，就会有 TIME_WAIT状态 **
- 四次挥手是指断开一个TCP连接时，需要[客户端]()和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由[客户端]()或服务端任一方执行close来触发 
- 由于TCP连接时全双工的，因此，每个方向的数据传输通道都必须要单独进行关闭。

# 34. MTU和MMS

![image-20210828113315085](C:\Users\78620\AppData\Roaming\Typora\typora-user-images\image-20210828113315085.png)

# 35. ICMP

原文链接: https://blog.csdn.net/m0_37268841/article/details/109165302

![image-20210828113829954](C:\Users\78620\AppData\Roaming\Typora\typora-user-images\image-20210828113829954.png)

**ICMP是Internet控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。**

在RFC，将ICMP 大致分成两种功能：差错通知和信息查询。

![img](https://img-blog.csdnimg.cn/img_convert/f09778c92ed6c065da04639e47e377b0.png)

[1]给送信者的错误通知；[2]送信者的信息查询。

[1]是到IP 数据包被对方的计算机处理的过程中，发生了什么错误时被使用。不仅传送发生了错误这个事实，也传送错误原因等消息。

[2]的信息询问是在送信方的计算机向对方计算机询问信息时被使用。被询问内容的种类非常丰富，他们有目标IP 地址的机器是否存在这种基本确认，调查自己网络的子网掩码，取得对方机器的时间信息等。









